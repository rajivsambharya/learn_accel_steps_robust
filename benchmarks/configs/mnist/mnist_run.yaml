nn_cfg:
  lr: 1e-2
  method: adam
  intermediate_layer_sizes: []
  batch_size: 1000
  epochs: 5000


data:
  datetime: ''

eval_every_x_epochs: 50
save_every_x_epochs: 1
test_every_x_epochs: 1
write_csv_every_x_batches: 1
epochs_jit: 2

N_train: 10
N_test: 10
N_val: 0
num_samples_train: 10
num_samples_test: 10
# num_const_steps: 1


prediction_variable: w
angle_anchors: [0]
plot_iterates: [0, 30]
loss_method: 'fixed_k' #'fixed_k' #'constant_sum'
# share_all: False
num_clusters: 10
pretrain_alpha: False
normalize_inputs: False
normalize_alpha: 'other'

accuracies: [.1, .01, .001, .0001]

# visualize
iterates_visualize: [3, 4, 5]
vis_num: 5
skip_startup: False

eval_unrolls: 100 #40000
supervised: True
train_unrolls: 60

custom_loss: False #True
algo: lah


pep_regularizer_coeff: 0
pep_target: 0.005